{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 5: machine teaching for kNN\n",
    "---\n",
    "Ruixuan Tu (ruixuan@cs.wisc.edu)\n",
    "\n",
    "29 March 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"hw5bdata.txt\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SHA\n",
    "using Random\n",
    "using Tidier\n",
    "using Gadfly\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Combinatorics\n",
    "using StatsBase\n",
    "using JSONTables\n",
    "\n",
    "cd(\"/Users/turx/Projects/machine-teaching-23sp/hw05-machine-teaching-knn\")\n",
    "Random.seed!(sum(sha256(\"machine-teaching\")))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pool = CSV.read(data_file, delim=' ', header=[:x1, :x2, :y], DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pool, x=:x1, y=:x2, color=:y, Geom.point, Scale.color_discrete)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants for Problem Setting in Homework Section 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1  # number of nearest neighbors\n",
    "Z = @chain pool begin  # superset of all teaching sets\n",
    "  @rename(x1p = x1, x2p = x2, yp = y)\n",
    "end\n",
    "enum_upper = 3  # n_star for enum, threshold for the number of teaching examples\n",
    "greedy_upper = 20  # n_star for greedy, threshold for the number of teaching examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the kNN classifier for arbitrary k and arbitrary number of dimensions\n",
    "# train_x: training data matrix, each row is a data point\n",
    "# train_y: training label vector\n",
    "# test_x: test data matrix, each row is a data point\n",
    "# k: number of nearest neighbors\n",
    "# return: predicted labels y-hat for test_x\n",
    "function knn_classifier(train_x, train_y, test_x, k)\n",
    "  test_y = zeros(Float64, size(test_x, 1))\n",
    "  for i in 1:size(test_x, 1)\n",
    "    dist = [sqrt(sum((train_x[j, ] - test_x[i, ]) ^ 2)) for j in 1:size(train_x, 1)]\n",
    "    knn = sortperm(dist)[1:k]\n",
    "    test_y[i] = mode(train_y[knn])\n",
    "  end\n",
    "  return test_y\n",
    "end\n",
    "\n",
    "# Predict the label of a single point using kNN classifier\n",
    "# x1: vector of first dimension of data points\n",
    "# x2: vector of second dimension of data points\n",
    "# y: vector of labels\n",
    "# x1p: position of the first dimension of the point to be labeled\n",
    "# x2p: position of the second dimension of the point to be labeled\n",
    "# k: number of nearest neighbors\n",
    "# return: predicted label y-hat for the point (x1p, x2p)\n",
    "function knn_classifier_single(x1, x2, y, x1p, x2p, k)\n",
    "  train_x = vcat(x1', x2')'\n",
    "  train_y = y\n",
    "  test_x = [x1p x2p]\n",
    "  return knn_classifier(train_x, train_y, test_x, k)[1]\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximation and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary loss function\n",
    "# y: vector of true labels\n",
    "# yp: vector of predicted labels\n",
    "# return: binary loss\n",
    "function loss_bin(y, yp)\n",
    "  return sum(y .!= yp) / length(y)\n",
    "end\n",
    "\n",
    "# Metric between functions f and g defined by equation (3)\n",
    "# Z: data frame (x1p, x2p, yp), x1p and x2p are positions of the points to be labeled, yp is the expected label\n",
    "# f: function f, the predictor with arguments x1p, x2p, returning yp (i.e., y-hat)\n",
    "# l: loss function, taking two vectors of labels and returning a scalar of total loss\n",
    "function dist(Z, f, l)\n",
    "  m = size(Z, 1)\n",
    "  pred = f.(Z.x1p, Z.x2p)\n",
    "  d = l(Z.yp, pred)\n",
    "  return d\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time the execution of an expression\n",
    "# return: tuple of (time in seconds, return value of f)\n",
    "macro timed_run(expr)\n",
    "    return quote\n",
    "        local t0 = time()\n",
    "        local ret = $(esc(expr))\n",
    "        local t1 = time()\n",
    "        ((t1 - t0), ret)\n",
    "    end\n",
    "end\n",
    "\n",
    "# Run the function and save or load the resulting DataFrame from a csv file\n",
    "# expr: expression to be run\n",
    "# file: file to save or load the result\n",
    "# return: DataFrame\n",
    "macro saved_run(expr, file)\n",
    "  return quote\n",
    "    if isfile($file)\n",
    "      CSV.read($file, DataFrame)\n",
    "    else\n",
    "      local df = $expr\n",
    "      CSV.write($file, df)\n",
    "      df\n",
    "    end\n",
    "  end\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function enum_timed(m)\n",
    "  best_d = Inf\n",
    "  best_subset = nothing\n",
    "  index_subsets = with_replacement_combinations(1:size(Z, 1), m)\n",
    "  counter = 0\n",
    "  for index_subset in index_subsets\n",
    "    subset = pool[index_subset, :]\n",
    "    counter += 1\n",
    "    g = (x1p, x2p) -> knn_classifier_single(subset.x1, subset.x2, subset.y, x1p, x2p, k)\n",
    "    d = dist(Z, g, loss_bin)\n",
    "    if d < best_d\n",
    "      best_d = d\n",
    "      best_subset = subset\n",
    "    end\n",
    "  end\n",
    "  return (counter, best_d, best_subset)\n",
    "end\n",
    "\n",
    "# Implementation of the enumeration algorithm\n",
    "# Reporting:\n",
    "# 1. the number of teaching sets of that size that you have to search through;\n",
    "# 2. number of seconds it takes for that size;\n",
    "# 3. d(kNN(D), g) of the best teaching set of that size;\n",
    "# 4. plot the best teaching set D-hat in relation to P (i.e. plot both, but use different symbols for D-hat)\n",
    "function enum_run()\n",
    "  results = DataFrame(\n",
    "    subset_sz = Int64[],\n",
    "    subset_n = Int64[],\n",
    "    time = Float64[],\n",
    "    d = Float64[],\n",
    "    subset = String[],\n",
    "  )\n",
    "  for m in 1:enum_upper\n",
    "    (t, r) = @timed_run enum_timed(m)\n",
    "    rs = objecttable(r[3])\n",
    "    push!(results, (m, r[1], t, r[2], rs))\n",
    "  end\n",
    "  return results\n",
    "end\n",
    "\n",
    "enum_results = @saved_run enum_run() \"enum.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots: negative integer $-x$ in color means the point $x-1$ is picked by the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function enum_plot(m)\n",
    "  best_subset = DataFrame(jsontable(enum_results.subset[m]))\n",
    "  best_d = enum_results.d[m]\n",
    "  best_subset.y = -best_subset.y .- 1\n",
    "  return plot(\n",
    "    layer(best_subset, x=:x1, y=:x2, color=:y, Geom.point),\n",
    "    layer(pool, x=:x1, y=:x2, color=:y, Geom.point),\n",
    "    Guide.title(\"Enumeration: Best Teaching Set vs Pool: m = $m, d = $best_d\"),\n",
    "    Scale.color_discrete\n",
    "  )\n",
    "end\n",
    "\n",
    "for m in 1:enum_upper\n",
    "  p = enum_plot(m)\n",
    "  draw(SVG(\"enum_m$m.svg\"), p)\n",
    "  display(p)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function greedy_timed(prev_D)\n",
    "  best_d = Inf\n",
    "  idx_l = []\n",
    "  for i in 1:size(pool, 1)\n",
    "    D = vcat(prev_D, i)\n",
    "    subset = pool[D, :]\n",
    "    g = (x1p, x2p) -> knn_classifier_single(subset.x1, subset.x2, subset.y, x1p, x2p, k)\n",
    "    d = dist(Z, g, loss_bin)\n",
    "    if d < best_d\n",
    "      best_d = d\n",
    "      idx_l = [i]\n",
    "    elseif d == best_d\n",
    "      push!(idx_l, i)\n",
    "    end\n",
    "  end\n",
    "  idx_to_add = rand(idx_l)\n",
    "  return (size(pool, 1), best_d, idx_to_add)\n",
    "end\n",
    "\n",
    "# Implementation of the greedy algorithm\n",
    "# Reporting:\n",
    "# 1. the number of teaching sets of that size that you have to search through;\n",
    "# 2. number of seconds it takes for that size;\n",
    "# 3. d(kNN(D), g) of the best teaching set of that size;\n",
    "# 4. plot one figure for the last teaching set D-hat with size n* in relation to P\n",
    "function greedy_run()\n",
    "  results = DataFrame(\n",
    "    subset_sz = Int64[],\n",
    "    subset_n = Int64[],\n",
    "    time = Float64[],\n",
    "    d = Float64[],\n",
    "    index = Int64[],\n",
    "  )\n",
    "  prev_D = []\n",
    "  for m in 1:greedy_upper\n",
    "    if m > 1\n",
    "      push!(prev_D, results.index[m - 1])\n",
    "    end\n",
    "    (t, r) = @timed_run greedy_timed(m)\n",
    "    push!(results, (m, r[1], t, r[2], r[3]))\n",
    "  end\n",
    "  return results\n",
    "end\n",
    "\n",
    "greedy_results = @saved_run greedy_run() \"greedy.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pool = pool[greedy_results.index, :]\n",
    "selected_pool.y = -selected_pool.y .- 1\n",
    "last_d = greedy_results.d[greedy_upper]\n",
    "\n",
    "p = plot(\n",
    "  layer(selected_pool, x=:x1, y=:x2, color=:y, Geom.point),\n",
    "  layer(pool, x=:x1, y=:x2, color=:y, Geom.point),\n",
    "  Guide.title(\"Greedy: Last Teaching Set vs Pool: m = $greedy_upper, d = $last_d\"),\n",
    "  Scale.color_discrete\n",
    ")\n",
    "draw(SVG(\"greedy_m$greedy_upper.svg\"), p)\n",
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
